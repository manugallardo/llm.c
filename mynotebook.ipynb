{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cLWy7Gvp5htoWFqXV-YktoRL2v5jFYEF","timestamp":1715714448166}],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1LwJ0ZLctqB1yjL69a_MUQ_57-hszuvfV","authorship_tag":"ABX9TyM8Jn/SRkWOaatJfeVK7YNr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup steps"],"metadata":{"id":"4aSQJ2e6lQ2Y"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"T8Wx-PDUjK9D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715799031777,"user_tz":240,"elapsed":137555,"user":{"displayName":"Manuel Gallardo","userId":"08339014208900483077"}},"outputId":"77dc11f0-a098-4e00-b441-34195d338f0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.2.1+cu121)\n","Collecting tiktoken (from -r requirements.txt (line 4))\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.40.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 3))\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->-r requirements.txt (line 4)) (2023.12.25)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (6.0.1)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.4.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 tiktoken-0.7.0\n","data/tiny_shakespeare.txt already exists, skipping download...\n","Saved 32768 tokens to data/tiny_shakespeare_val.bin\n","Saved 305260 tokens to data/tiny_shakespeare_train.bin\n","Running pytorch 2.2.1+cu121\n","using device: cuda\n","wrote gpt2_tokenizer.bin\n","loading weights from pretrained gpt: gpt2\n","config.json: 100% 665/665 [00:00<00:00, 3.96MB/s]\n","model.safetensors: 100% 548M/548M [00:02<00:00, 201MB/s]\n","generation_config.json: 100% 124/124 [00:00<00:00, 808kB/s]\n","loading cached tokens in data/tiny_shakespeare_val.bin\n","padded vocab size from 50257 to 50304\n","wrote gpt2_124M.bin\n","padded vocab size from 50257 to 50304\n","wrote gpt2_124M_bf16.bin\n","padded vocab size in reference grads from 50257 to 50304\n","wrote gpt2_124M_debug_state.bin\n","iteration 1, loss: 5.2700, time: 99.221ms, tok/s: 2580.09\n","iteration 2, loss: 4.0597, time: 43.395ms, tok/s: 5899.36\n","iteration 3, loss: 3.3752, time: 32.398ms, tok/s: 7901.61\n","iteration 4, loss: 2.8008, time: 31.646ms, tok/s: 8089.49\n","iteration 5, loss: 2.3154, time: 31.592ms, tok/s: 8103.28\n","iteration 6, loss: 1.8490, time: 31.555ms, tok/s: 8112.77\n","iteration 7, loss: 1.3946, time: 31.233ms, tok/s: 8196.38\n","iteration 8, loss: 0.9992, time: 28.874ms, tok/s: 8866.06\n","iteration 9, loss: 0.6241, time: 28.892ms, tok/s: 8860.65\n","iteration 10, loss: 0.3765, time: 29.603ms, tok/s: 8647.63\n","final 9 iters avg: 32.132ms\n","peak memory consumption: 2390 MiB\n","<|endoftext|>One year ago today:\n","This is the first week since we last spoke.\n","---------------\n","---------------------------------------------\n","→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n","✓ OpenMP found\n","✓ OpenMPI found, OK to train with multiple GPUs\n","✓ nvcc found, including GPU/CUDA support\n","---------------------------------------------\n","/usr/local/cuda/bin/nvcc -O3 -t=0 --use_fast_math --generate-code arch=compute_80,code=[compute_80,sm_80] -DMULTI_GPU train_gpt2_fp32.cu -lcublas -lcublasLt -L/usr/lib/x86_64-linux-gnu/openmpi/lib/ -I/usr/lib/x86_64-linux-gnu/openmpi/include -lmpi -lnccl -o train_gpt2fp32cu\n","+-----------------------+----------------------------------------------------+\n","| Parameter             | Value                                              |\n","+-----------------------+----------------------------------------------------+\n","| input dataset prefix  | data/tiny_shakespeare                              |\n","| output log file       | NULL                                               |\n","| batch size B          | 4                                                  |\n","| sequence length T     | 1024                                               |\n","| learning rate         | 0.000300                                           |\n","| val_loss_every        | 20                                                 |\n","| val_max_batches       | 20                                                 |\n","| sample_every          | 20                                                 |\n","| genT                  | 64                                                 |\n","+-----------------------+----------------------------------------------------+\n","| device                | NVIDIA A100-SXM4-40GB                              |\n","| TF32                  | enabled                                            |\n","+-----------------------+----------------------------------------------------+\n","| max_sequence_length T | 1024                                               |\n","| vocab_size V          | 50257                                              |\n","| padded_vocab_size Vp  | 50304                                              |\n","| num_layers L          | 12                                                 |\n","| num_heads NH          | 12                                                 |\n","| channels C            | 768                                                |\n","| num_parameters        | 124475904                                          |\n","+-----------------------+----------------------------------------------------+\n","| train_num_batches     | 74                                                 |\n","| val_num_batches       | 20                                                 |\n","+-----------------------+----------------------------------------------------+\n","allocated 474 MiB for model parameters\n","allocated 5706 MiB for activations\n","val loss 4.506244\n","allocated 474 MiB for parameter gradients\n","allocated 252 MiB for activation gradients\n","allocated 474 MiB for AdamW optimizer state m\n","allocated 474 MiB for AdamW optimizer state v\n","step    1/74: train loss 4.367631 (64.741007 ms, 63267 tok/s)\n","step    2/74: train loss 4.435826 (59.127320 ms, 69274 tok/s)\n","step    3/74: train loss 4.346059 (59.010164 ms, 69411 tok/s)\n","step    4/74: train loss 3.915845 (59.048417 ms, 69366 tok/s)\n","step    5/74: train loss 3.576457 (59.093490 ms, 69313 tok/s)\n","step    6/74: train loss 3.752738 (59.217720 ms, 69168 tok/s)\n","step    7/74: train loss 3.543775 (59.009138 ms, 69412 tok/s)\n","step    8/74: train loss 3.691608 (59.084189 ms, 69324 tok/s)\n","step    9/74: train loss 3.291923 (59.304025 ms, 69067 tok/s)\n","step   10/74: train loss 3.420156 (59.422621 ms, 68929 tok/s)\n","step   11/74: train loss 3.839075 (59.521577 ms, 68815 tok/s)\n","step   12/74: train loss 3.459750 (59.537874 ms, 68796 tok/s)\n","step   13/74: train loss 3.617115 (59.388497 ms, 68969 tok/s)\n","step   14/74: train loss 3.230589 (59.424002 ms, 68928 tok/s)\n","step   15/74: train loss 3.669843 (59.387571 ms, 68970 tok/s)\n","step   16/74: train loss 3.859624 (62.457402 ms, 65580 tok/s)\n","step   17/74: train loss 3.851252 (59.527662 ms, 68808 tok/s)\n","step   18/74: train loss 3.919990 (59.423148 ms, 68929 tok/s)\n","step   19/74: train loss 3.638858 (59.406154 ms, 68949 tok/s)\n","step   20/74: train loss 3.733744 (59.410895 ms, 68943 tok/s)\n","val loss 3.687467\n","generating:\n","---\n","O, my cousin: that is so.\n","\n","<|endoftext|>O<|endoftext|>No, my brothers; I die in a stroke:\n","Shall there be two in bloom,\n","Even in a day's life so terrible\n","Where the lovers have lived to-day\n","The melancholy tears were heard, the repetition was darling\n","\n","---\n","step   21/74: train loss 3.719474 (59.660196 ms, 68655 tok/s)\n","step   22/74: train loss 3.586015 (59.558152 ms, 68773 tok/s)\n","step   23/74: train loss 3.551630 (59.717257 ms, 68589 tok/s)\n","step   24/74: train loss 3.351470 (59.676127 ms, 68637 tok/s)\n","step   25/74: train loss 3.454458 (59.583548 ms, 68743 tok/s)\n","step   26/74: train loss 3.760597 (59.492449 ms, 68849 tok/s)\n","step   27/74: train loss 3.778916 (59.549206 ms, 68783 tok/s)\n","step   28/74: train loss 3.636331 (59.417618 ms, 68935 tok/s)\n","step   29/74: train loss 3.448246 (59.522523 ms, 68814 tok/s)\n","step   30/74: train loss 3.574257 (59.487426 ms, 68854 tok/s)\n","step   31/74: train loss 3.509093 (59.508909 ms, 68830 tok/s)\n","step   32/74: train loss 3.361974 (59.388415 ms, 68969 tok/s)\n","step   33/74: train loss 3.420916 (59.416811 ms, 68936 tok/s)\n","step   34/74: train loss 3.684297 (59.390063 ms, 68967 tok/s)\n","step   35/74: train loss 3.381581 (59.395836 ms, 68961 tok/s)\n","step   36/74: train loss 3.401357 (59.291206 ms, 69082 tok/s)\n","step   37/74: train loss 3.812554 (59.426366 ms, 68925 tok/s)\n","step   38/74: train loss 3.623046 (59.211715 ms, 69175 tok/s)\n","step   39/74: train loss 3.489915 (59.337865 ms, 69028 tok/s)\n","step   40/74: train loss 3.137510 (59.555248 ms, 68776 tok/s)\n","val loss 3.635556\n","generating:\n","---\n","い Aadhaar thee,\n","Like a crest, plans thy uncouth life: He whereof I cannot hear fear.\n","With stifled music, and not with any rites,\n","Some unseen mysteries rest on drunken bustle,\n","Till dark night-time o'er a whereabouts;\n","For at\n","---\n","step   41/74: train loss 3.477242 (59.555664 ms, 68775 tok/s)\n","step   42/74: train loss 3.330773 (59.437737 ms, 68912 tok/s)\n","step   43/74: train loss 3.477144 (59.509052 ms, 68829 tok/s)\n","step   44/74: train loss 3.366627 (59.449111 ms, 68899 tok/s)\n","step   45/74: train loss 3.978860 (59.423105 ms, 68929 tok/s)\n","step   46/74: train loss 3.866296 (59.445739 ms, 68903 tok/s)\n","step   47/74: train loss 3.774393 (59.370627 ms, 68990 tok/s)\n","step   48/74: train loss 3.963144 (59.417356 ms, 68936 tok/s)\n","step   49/74: train loss 4.035960 (59.379080 ms, 68980 tok/s)\n","step   50/74: train loss 3.856818 (59.217190 ms, 69169 tok/s)\n","step   51/74: train loss 3.604803 (59.080718 ms, 69328 tok/s)\n","step   52/74: train loss 3.578928 (59.245845 ms, 69135 tok/s)\n","step   53/74: train loss 3.823999 (59.682032 ms, 68630 tok/s)\n","step   54/74: train loss 3.765675 (59.749486 ms, 68552 tok/s)\n","step   55/74: train loss 3.487754 (59.717559 ms, 68589 tok/s)\n","step   56/74: train loss 3.151937 (59.632766 ms, 68687 tok/s)\n","step   57/74: train loss 3.344817 (59.625066 ms, 68695 tok/s)\n","step   58/74: train loss 3.522411 (59.541331 ms, 68792 tok/s)\n","step   59/74: train loss 3.374256 (59.485682 ms, 68856 tok/s)\n","step   60/74: train loss 3.433411 (59.621006 ms, 68700 tok/s)\n","val loss 3.530005\n","generating:\n","---\n","'theAim's down, with the paltry aim, foretell'd; for the king may take it, whose son\n","I have but lov'd to-morrow; how should the man recollect this?\n","Still but one-hundred and now taking form\n","After the eternal reunion between ourselves.\n","---\n","step   61/74: train loss 3.322723 (59.769373 ms, 68530 tok/s)\n","step   62/74: train loss 3.263739 (59.494371 ms, 68846 tok/s)\n","step   63/74: train loss 3.288531 (59.285658 ms, 69089 tok/s)\n","step   64/74: train loss 3.792963 (59.205135 ms, 69183 tok/s)\n","step   65/74: train loss 3.561049 (59.282614 ms, 69092 tok/s)\n","step   66/74: train loss 3.339418 (59.563965 ms, 68766 tok/s)\n","step   67/74: train loss 3.233123 (59.699565 ms, 68610 tok/s)\n","step   68/74: train loss 3.424434 (59.701751 ms, 68607 tok/s)\n","step   69/74: train loss 3.260159 (59.737849 ms, 68566 tok/s)\n","step   70/74: train loss 3.071431 (59.606635 ms, 68717 tok/s)\n","step   71/74: train loss 3.048734 (59.580523 ms, 68747 tok/s)\n","step   72/74: train loss 3.058115 (59.526891 ms, 68809 tok/s)\n","step   73/74: train loss 3.697622 (59.526911 ms, 68809 tok/s)\n","step   74/74: train loss 3.498255 (59.633142 ms, 68686 tok/s)\n","val loss 3.515384\n","generating:\n","---\n","A stamp as answer to them:\n","When you save yourself from the time's are you ready\n","For an amorous encounter in a book.\n","\n","<|endoftext|>TURPRIXENTIO:\n","Well said, thou guess'd not, but sovereignty\n","Because you did all wet your countenance.\n","\n","<|endoftext|>HORT\n","---\n","total average iteration time: 59.558518 ms\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":1}],"source":["%%shell\n","cd drive/MyDrive/llm.c/\n","pip install -r requirements.txt\n","python prepro_tinyshakespeare.py\n","python train_gpt2.py\n","make train_gpt2fp32cu\n","./train_gpt2fp32cu"]},{"cell_type":"code","source":["%%shell\n","sudo apt install neovim"],"metadata":{"id":"SMp-pF6kqUfN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715799045199,"user_tz":240,"elapsed":11613,"user":{"displayName":"Manuel Gallardo","userId":"08339014208900483077"}},"outputId":"d33b720a-af0a-4ff9-d178-60e7e1f41ef8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libluajit-5.1-2 libluajit-5.1-common libmsgpackc2 libtermkey1\n","  libtree-sitter0 libunibilium4 libvterm0 lua-luv neovim-runtime\n","  python3-greenlet python3-msgpack python3-neovim python3-pynvim\n","Suggested packages:\n","  ctags vim-scripts python-greenlet-dev python-greenlet-doc\n","The following NEW packages will be installed:\n","  libluajit-5.1-2 libluajit-5.1-common libmsgpackc2 libtermkey1\n","  libtree-sitter0 libunibilium4 libvterm0 lua-luv neovim neovim-runtime\n","  python3-greenlet python3-msgpack python3-neovim python3-pynvim\n","0 upgraded, 14 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 6,633 kB of archives.\n","After this operation, 27.4 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libluajit-5.1-common all 2.1.0~beta3+dfsg-6 [44.3 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libluajit-5.1-2 amd64 2.1.0~beta3+dfsg-6 [238 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtree-sitter0 amd64 0.20.3-1 [86.5 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libunibilium4 amd64 2.1.0-1 [22.6 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-luv amd64 1.36.0-0-1 [84.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-msgpack amd64 1.0.3-1build1 [67.8 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-greenlet amd64 1.1.2-3build1 [65.0 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pynvim all 0.4.2-1 [31.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-neovim all 0.4.2-1 [1,804 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmsgpackc2 amd64 3.3.0-4 [15.1 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtermkey1 amd64 0.22-1 [18.5 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvterm0 amd64 0.1.4-1 [29.7 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 neovim-runtime all 0.6.1-3 [4,115 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 neovim amd64 0.6.1-3 [1,814 kB]\n","Fetched 6,633 kB in 2s (2,855 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 14.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libluajit-5.1-common.\n","(Reading database ... 121918 files and directories currently installed.)\n","Preparing to unpack .../00-libluajit-5.1-common_2.1.0~beta3+dfsg-6_all.deb ...\n","Unpacking libluajit-5.1-common (2.1.0~beta3+dfsg-6) ...\n","Selecting previously unselected package libluajit-5.1-2:amd64.\n","Preparing to unpack .../01-libluajit-5.1-2_2.1.0~beta3+dfsg-6_amd64.deb ...\n","Unpacking libluajit-5.1-2:amd64 (2.1.0~beta3+dfsg-6) ...\n","Selecting previously unselected package libtree-sitter0:amd64.\n","Preparing to unpack .../02-libtree-sitter0_0.20.3-1_amd64.deb ...\n","Unpacking libtree-sitter0:amd64 (0.20.3-1) ...\n","Selecting previously unselected package libunibilium4:amd64.\n","Preparing to unpack .../03-libunibilium4_2.1.0-1_amd64.deb ...\n","Unpacking libunibilium4:amd64 (2.1.0-1) ...\n","Selecting previously unselected package lua-luv:amd64.\n","Preparing to unpack .../04-lua-luv_1.36.0-0-1_amd64.deb ...\n","Unpacking lua-luv:amd64 (1.36.0-0-1) ...\n","Selecting previously unselected package python3-msgpack.\n","Preparing to unpack .../05-python3-msgpack_1.0.3-1build1_amd64.deb ...\n","Unpacking python3-msgpack (1.0.3-1build1) ...\n","Selecting previously unselected package python3-greenlet.\n","Preparing to unpack .../06-python3-greenlet_1.1.2-3build1_amd64.deb ...\n","Unpacking python3-greenlet (1.1.2-3build1) ...\n","Selecting previously unselected package python3-pynvim.\n","Preparing to unpack .../07-python3-pynvim_0.4.2-1_all.deb ...\n","Unpacking python3-pynvim (0.4.2-1) ...\n","Selecting previously unselected package python3-neovim.\n","Preparing to unpack .../08-python3-neovim_0.4.2-1_all.deb ...\n","Unpacking python3-neovim (0.4.2-1) ...\n","Selecting previously unselected package libmsgpackc2:amd64.\n","Preparing to unpack .../09-libmsgpackc2_3.3.0-4_amd64.deb ...\n","Unpacking libmsgpackc2:amd64 (3.3.0-4) ...\n","Selecting previously unselected package libtermkey1:amd64.\n","Preparing to unpack .../10-libtermkey1_0.22-1_amd64.deb ...\n","Unpacking libtermkey1:amd64 (0.22-1) ...\n","Selecting previously unselected package libvterm0:amd64.\n","Preparing to unpack .../11-libvterm0_0.1.4-1_amd64.deb ...\n","Unpacking libvterm0:amd64 (0.1.4-1) ...\n","Selecting previously unselected package neovim-runtime.\n","Preparing to unpack .../12-neovim-runtime_0.6.1-3_all.deb ...\n","Unpacking neovim-runtime (0.6.1-3) ...\n","Selecting previously unselected package neovim.\n","Preparing to unpack .../13-neovim_0.6.1-3_amd64.deb ...\n","Unpacking neovim (0.6.1-3) ...\n","Setting up libunibilium4:amd64 (2.1.0-1) ...\n","Setting up neovim-runtime (0.6.1-3) ...\n","Setting up libmsgpackc2:amd64 (3.3.0-4) ...\n","Setting up libvterm0:amd64 (0.1.4-1) ...\n","Setting up lua-luv:amd64 (1.36.0-0-1) ...\n","Setting up libtree-sitter0:amd64 (0.20.3-1) ...\n","Setting up python3-greenlet (1.1.2-3build1) ...\n","Setting up libluajit-5.1-common (2.1.0~beta3+dfsg-6) ...\n","Setting up libtermkey1:amd64 (0.22-1) ...\n","Setting up python3-msgpack (1.0.3-1build1) ...\n","Setting up libluajit-5.1-2:amd64 (2.1.0~beta3+dfsg-6) ...\n","Setting up python3-pynvim (0.4.2-1) ...\n","Setting up python3-neovim (0.4.2-1) ...\n","Setting up neovim (0.6.1-3) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":2}]}]}